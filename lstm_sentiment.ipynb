{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Long Short-term Memory for Sentiment Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses LSTM neural network on the [IMDB sentiment classification](https://keras.io/api/datasets/imdb/) task. This is a dataset for binary sentiment classification. 25,000 highly polar movie reviews are provided for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing import sequence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the data\n",
    "IMDB sentiment dataset is available in keras.datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function load_data in module tensorflow.python.keras.datasets.imdb:\n",
      "\n",
      "load_data(path='imdb.npz', num_words=None, skip_top=0, maxlen=None, seed=113, start_char=1, oov_char=2, index_from=3, **kwargs)\n",
      "    Loads the [IMDB dataset](https://ai.stanford.edu/~amaas/data/sentiment/).\n",
      "    \n",
      "    This is a dataset of 25,000 movies reviews from IMDB, labeled by sentiment\n",
      "    (positive/negative). Reviews have been preprocessed, and each review is\n",
      "    encoded as a list of word indexes (integers).\n",
      "    For convenience, words are indexed by overall frequency in the dataset,\n",
      "    so that for instance the integer \"3\" encodes the 3rd most frequent word in\n",
      "    the data. This allows for quick filtering operations such as:\n",
      "    \"only consider the top 10,000 most\n",
      "    common words, but eliminate the top 20 most common words\".\n",
      "    \n",
      "    As a convention, \"0\" does not stand for a specific word, but instead is used\n",
      "    to encode any unknown word.\n",
      "    \n",
      "    Args:\n",
      "      path: where to cache the data (relative to `~/.keras/dataset`).\n",
      "      num_words: integer or None. Words are\n",
      "          ranked by how often they occur (in the training set) and only\n",
      "          the `num_words` most frequent words are kept. Any less frequent word\n",
      "          will appear as `oov_char` value in the sequence data. If None,\n",
      "          all words are kept. Defaults to None, so all words are kept.\n",
      "      skip_top: skip the top N most frequently occurring words\n",
      "          (which may not be informative). These words will appear as\n",
      "          `oov_char` value in the dataset. Defaults to 0, so no words are\n",
      "          skipped.\n",
      "      maxlen: int or None. Maximum sequence length.\n",
      "          Any longer sequence will be truncated. Defaults to None, which\n",
      "          means no truncation.\n",
      "      seed: int. Seed for reproducible data shuffling.\n",
      "      start_char: int. The start of a sequence will be marked with this\n",
      "          character. Defaults to 1 because 0 is usually the padding character.\n",
      "      oov_char: int. The out-of-vocabulary character.\n",
      "          Words that were cut out because of the `num_words` or\n",
      "          `skip_top` limits will be replaced with this character.\n",
      "      index_from: int. Index actual words with this index and higher.\n",
      "      **kwargs: Used for backwards compatibility.\n",
      "    \n",
      "    Returns:\n",
      "      Tuple of Numpy arrays: `(x_train, y_train), (x_test, y_test)`.\n",
      "    \n",
      "    **x_train, x_test**: lists of sequences, which are lists of indexes\n",
      "      (integers). If the num_words argument was specific, the maximum\n",
      "      possible index value is `num_words - 1`. If the `maxlen` argument was\n",
      "      specified, the largest possible sequence length is `maxlen`.\n",
      "    \n",
      "    **y_train, y_test**: lists of integer labels (1 or 0).\n",
      "    \n",
      "    Raises:\n",
      "      ValueError: in case `maxlen` is so low\n",
      "          that no input sequence could be kept.\n",
      "    \n",
      "    Note that the 'out of vocabulary' character is only used for\n",
      "    words that were present in the training set but are not included\n",
      "    because they're not making the `num_words` cut here.\n",
      "    Words that were not seen in the training set but are in the test set\n",
      "    have simply been skipped.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(imdb.load_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:155: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/keras/datasets/imdb.py:156: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "max_features = 20000\n",
    "maxlen = 80\n",
    "# maxlen: cut texts after this number of words (among top max_features most common words)\n",
    "batch_size = 32\n",
    "\n",
    "print('Loading data...')\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "Keras has already preprocessed the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad sequences (samples x time)\n",
      "X_train shape: (25000, 80)\n",
      "X_test shape: (25000, 80)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 125,   68,    2, 6853,   15,  349,  165, 4362,   98,    5,    4,\n",
       "        228,    9,   43,    2, 1157,   15,  299,  120,    5,  120,  174,\n",
       "         11,  220,  175,  136,   50,    9, 4373,  228, 8255,    5,    2,\n",
       "        656,  245, 2350,    5,    4, 9837,  131,  152,  491,   18,    2,\n",
       "         32, 7464, 1212,   14,    9,    6,  371,   78,   22,  625,   64,\n",
       "       1382,    9,    8,  168,  145,   23,    4, 1690,   15,   16,    4,\n",
       "       1355,    5,   28,    6,   52,  154,  462,   33,   89,   78,  285,\n",
       "         16,  145,   95], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Pad sequences (samples x time)')\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('X_test shape:', X_test.shape)\n",
    "X_train[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16))\n",
    "model.add(layers.SimpleRNN(32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model\n",
    "\n",
    "Use the `.summary` method to print a simple description of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 32)                1568      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 321,601\n",
      "Trainable params: 321,601\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "313/313 [==============================] - 6s 15ms/step - loss: 0.7013 - accuracy: 0.5005 - val_loss: 0.6872 - val_accuracy: 0.5424\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.6731 - accuracy: 0.5748 - val_loss: 0.5835 - val_accuracy: 0.6996\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 4s 14ms/step - loss: 0.5444 - accuracy: 0.7274 - val_loss: 0.5230 - val_accuracy: 0.7602\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.4429 - accuracy: 0.8026 - val_loss: 0.9065 - val_accuracy: 0.7028\n",
      "Epoch 5/32\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3964 - accuracy: 0.8294 - val_loss: 0.4848 - val_accuracy: 0.7810\n",
      "Epoch 6/32\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3652 - accuracy: 0.8479 - val_loss: 0.4059 - val_accuracy: 0.8176\n",
      "Epoch 7/32\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.3368 - accuracy: 0.8644 - val_loss: 0.5097 - val_accuracy: 0.8106\n",
      "Epoch 8/32\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3162 - accuracy: 0.8731 - val_loss: 0.6310 - val_accuracy: 0.7912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa59277ee80>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy: 78.16%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN using the entire sequence instead of the last output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 80, 16)            320000    \n",
      "_________________________________________________________________\n",
      "simple_rnn_1 (SimpleRNN)     (None, 80, 32)            1568      \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 2561      \n",
      "=================================================================\n",
      "Total params: 324,129\n",
      "Trainable params: 324,129\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16, input_length=maxlen))\n",
    "model.add(layers.SimpleRNN(32, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "313/313 [==============================] - 6s 15ms/step - loss: 0.7005 - accuracy: 0.5197 - val_loss: 0.6337 - val_accuracy: 0.6820\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 5s 16ms/step - loss: 0.4859 - accuracy: 0.7594 - val_loss: 0.3670 - val_accuracy: 0.8348\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.3209 - accuracy: 0.8605 - val_loss: 0.3637 - val_accuracy: 0.8434\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2655 - accuracy: 0.8905 - val_loss: 0.3518 - val_accuracy: 0.8450\n",
      "Epoch 5/32\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2337 - accuracy: 0.9050 - val_loss: 0.3687 - val_accuracy: 0.8476\n",
      "Epoch 6/32\n",
      "313/313 [==============================] - 5s 15ms/step - loss: 0.2045 - accuracy: 0.9199 - val_loss: 0.3834 - val_accuracy: 0.8420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa5c219aee0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy: 83.01%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16))\n",
    "model.add(layers.LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the model\n",
    "\n",
    "Use the `.summary` method to print a simple description of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 16)          320000    \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 128)               74240     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 394,369\n",
      "Trainable params: 394,369\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "313/313 [==============================] - 23s 65ms/step - loss: 0.5300 - accuracy: 0.7449 - val_loss: 0.4115 - val_accuracy: 0.8256\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 19s 61ms/step - loss: 0.3369 - accuracy: 0.8603 - val_loss: 0.3569 - val_accuracy: 0.8456\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.2840 - accuracy: 0.8844 - val_loss: 0.3470 - val_accuracy: 0.8490\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 20s 64ms/step - loss: 0.2483 - accuracy: 0.9015 - val_loss: 0.3547 - val_accuracy: 0.8474\n",
      "Epoch 5/32\n",
      "313/313 [==============================] - 19s 60ms/step - loss: 0.2303 - accuracy: 0.9129 - val_loss: 0.3786 - val_accuracy: 0.8454\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa5b196d3a0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy: 83.91%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacked LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 16)          320000    \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, None, 128)         74240     \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 525,953\n",
      "Trainable params: 525,953\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16))\n",
    "model.add(layers.LSTM(128, return_sequences=True, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "313/313 [==============================] - 45s 132ms/step - loss: 0.5047 - accuracy: 0.7484 - val_loss: 0.4167 - val_accuracy: 0.8234\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 44s 139ms/step - loss: 0.3336 - accuracy: 0.8612 - val_loss: 0.5216 - val_accuracy: 0.8244\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.2802 - accuracy: 0.8855 - val_loss: 0.3630 - val_accuracy: 0.8412\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.2499 - accuracy: 0.9029 - val_loss: 0.5825 - val_accuracy: 0.8138\n",
      "Epoch 5/32\n",
      "313/313 [==============================] - 43s 138ms/step - loss: 0.2296 - accuracy: 0.9099 - val_loss: 0.3626 - val_accuracy: 0.8428\n",
      "Epoch 6/32\n",
      "313/313 [==============================] - 46s 147ms/step - loss: 0.2098 - accuracy: 0.9198 - val_loss: 0.5436 - val_accuracy: 0.8294\n",
      "Epoch 7/32\n",
      "313/313 [==============================] - 45s 144ms/step - loss: 0.1998 - accuracy: 0.9255 - val_loss: 0.3799 - val_accuracy: 0.8412\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa5926442e0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set accuracy: 83.40%\n"
     ]
    }
   ],
   "source": [
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bidirectional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 16)          320000    \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               148480    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 468,737\n",
      "Trainable params: 468,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.Sequential()\n",
    "# Embedding layer turns vectors of integers into dense real vectors of fixed size\n",
    "model.add(layers.Embedding(max_features, 16))\n",
    "model.add(layers.Bidirectional(layers.LSTM(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.2)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "optimizer = optimizers.RMSprop(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32\n",
      "313/313 [==============================] - 34s 96ms/step - loss: 0.5161 - accuracy: 0.7369 - val_loss: 0.3840 - val_accuracy: 0.8386\n",
      "Epoch 2/32\n",
      "313/313 [==============================] - 29s 93ms/step - loss: 0.3292 - accuracy: 0.8626 - val_loss: 0.3500 - val_accuracy: 0.8500\n",
      "Epoch 3/32\n",
      "313/313 [==============================] - 29s 94ms/step - loss: 0.2698 - accuracy: 0.8923 - val_loss: 0.3617 - val_accuracy: 0.8486\n",
      "Epoch 4/32\n",
      "313/313 [==============================] - 30s 96ms/step - loss: 0.2350 - accuracy: 0.9106 - val_loss: 0.3503 - val_accuracy: 0.8460\n",
      "Testing set accuracy: 83.98%\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 32\n",
    "BATCH = 64\n",
    "\n",
    "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=BATCH,\n",
    "          epochs=EPOCHS,\n",
    "          validation_split=0.2,\n",
    "          verbose = 1,\n",
    "          callbacks = [early_stop])\n",
    "\n",
    "_, acc = model.evaluate(X_test, y_test, batch_size=64, verbose = 0)\n",
    "print(\"Testing set accuracy: {:.2f}%\".format(acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
